{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLCodeandReport",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoangnhan12-arc/CS114.K21.KHTN/blob/master/FinalMachineLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWbHaRQDyM7m",
        "colab_type": "text"
      },
      "source": [
        "# **ĐỒ ÁN CUỐI KÌ MÔN MÁY HỌC : PHÂN LOẠI ĐỀ TÀI DỰA VÀO TIÊU ĐỀ BÀI BÁO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCtXsFuWyVuy",
        "colab_type": "text"
      },
      "source": [
        "#**I. Mô tả bài toán:** \n",
        "##Đặt vấn đề:\n",
        "> Mạng xã hội ngày càng phát triển, các fanpage group xuất hiện ngày càng nhiều, với mục đích trao đổi, thảo luận, chia sẻ kinh nghiệm,... Với số lượng bài viết lớn và nhiều đề tài cần quản lý thì việc phân loại bài viết là hết sức cần thiết. Việc phân loại bài viết có thể được chính chúng ta đọc bài và phân chia vào từng loại chủ đề khác nhau, nhưng việc này tốn khá nhiều thời gian và công sức cũng như tiền bạc để chi trả cho các admin page.\n",
        "\n",
        "##Giải quyết vấn đề:\n",
        "> Nếu chúng ta có một hệ thống tự động giúp phân loại các bài viết dựa vào tiêu đề thì sẽ giải quyết được nhiều vấn đề ở trên( tiết kiệm thời gian, công sức và tiền bạc). Ta sẽ xây dựng một mô hình tiên đoán, giúp phân loại chủ đề bài viết dựa vào tiêu đề bài viết.\n",
        "\n",
        "##Mô tả mô hình:\n",
        ">Input: Một tiêu đề bài viết bất kì \n",
        "\n",
        ">Output: Tiêu đề đó thuộc chủ đề nào\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                     \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBXvzeAgHIJl",
        "colab_type": "text"
      },
      "source": [
        "# **II. MÔ TẢ DỮ LIỆU**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJBrt3S9khzF",
        "colab_type": "text"
      },
      "source": [
        "## 1. Chia lớp chủ đề: \n",
        ">Có 6 class dữ liệu:\n",
        "\n",
        "\n",
        "> *   Chính trị\n",
        "> *   Công nghệ\n",
        "> *   Giáo dục\n",
        "> *   Pháp luật\n",
        "> *   Thể thao\n",
        "> *   Kinh doanh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI6IehMmt_BI",
        "colab_type": "text"
      },
      "source": [
        "## 2. Nguồn thu thập dữ liệu:\n",
        ">Dữ liệu được crawl từ trang vietnamnet.vn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8-n488GJfTE",
        "colab_type": "text"
      },
      "source": [
        "## 3. Cách thu thập dữ liệu:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0SyWMhhXBBK",
        "colab_type": "text"
      },
      "source": [
        "***Khởi tạo hàm lấy content từ một trang web***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP6WihelXM3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "189ce1bd-8e05-49ea-ad2e-40128c96de15"
      },
      "source": [
        "!pip install pyvi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zr_DhQWXFAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bs4\n",
        "import pandas\n",
        "import requests\n",
        "import gensim \n",
        "from pyvi import ViTokenizer, ViPosTagger\n",
        "\n",
        "def get_page_content(url):\n",
        "   page = requests.get(url,headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36'})\n",
        "   return bs4.BeautifulSoup(page.text,\"html.parser\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Aw9fRAux-S",
        "colab_type": "text"
      },
      "source": [
        "***Ví dụ crawl data chính trị***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPvdhDcUUox7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chinhtri_titles = []\n",
        "for i in range (1, 501):\n",
        "  url = \"https://vietnamnet.vn/vn/thoi-su/chinh-tri/trang{}\".format(i)   #Load từ trang 1 đến trang 500 mục chính trị\n",
        "  soup = get_page_content(url)        #Lấy content từ một trang web\n",
        "  h3_contents = soup.findAll('h3')     #Tìm mục h3\n",
        "\n",
        "  new_titles = []\n",
        "  for h3_content in h3_contents:\n",
        "    if (h3_content.find('a')):          # Kiểm tra điều kiện để tránh bị lỗi trong quá trình crawl data\n",
        "      text = h3_content.find('a').text  # Trích xuất title \n",
        "      new_titles.append(text)\n",
        "  \n",
        "  chinhtri_titles += new_titles\n",
        "chinhtri_titles = list(set(chinhtri_titles))  # Loại bỏ các bộ trùng bằng kiểu dữ liệu set\n",
        "\n",
        "print(len(chinhtri_titles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Yuk5-EYgE-",
        "colab_type": "text"
      },
      "source": [
        "*** Crawl data về kinh doanh***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l6YuswZhJPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kinhdoanh_titles = []\n",
        "for i in range (1, 501):\n",
        "  url = \"https://vietnamnet.vn/vn/kinh-doanh/trang{}\".format(i)   #Load từ trang 1 đến trang 500 mục kinh doanh\n",
        "  soup = get_page_content(url)        #Lấy content từ một trang web\n",
        "  h3_contents = soup.findAll('h3')     #Tìm mục h3\n",
        "\n",
        "  new_titles = []\n",
        "  for h3_content in h3_contents:\n",
        "    if (h3_content.find('a')):          # Kiểm tra điều kiện để tránh bị lỗi trong quá trình crawl data\n",
        "      text = h3_content.find('a').text  # Trích xuất title \n",
        "      new_titles.append(text)\n",
        "  \n",
        "  kinhdoanh_titles += new_titles\n",
        "  \n",
        "kinhdoanh_titles = list(set(kinhdoanh_titles))  # Loại bỏ các bộ trùng bằng kiểu dữ liệu set\n",
        "\n",
        "print(len(kinhdoanh_titles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c65sy87uY3FR",
        "colab_type": "text"
      },
      "source": [
        "*** Crawl data về thể thao***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShgXvOccZpdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thethao_titles = []\n",
        "for i in range (1, 501):\n",
        "  url = \"https://vietnamnet.vn/vn/the-thao/trang{}\".format(i)\n",
        "  soup = get_page_content(url)\n",
        "  h3_contents = soup.findAll('h3')\n",
        "  \n",
        "  new_titles = []\n",
        "  for h3_content in h3_contents:\n",
        "    if (h3_content.find('a')):\n",
        "      text = h3_content.find('a').text\n",
        "      new_titles.append(text)\n",
        "  \n",
        "  thethao_titles += new_titles\n",
        "  \n",
        "thethao_titles = list(set(thethao_titles))\n",
        "print(len(thethao_titles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8YQOVqcZrwA",
        "colab_type": "text"
      },
      "source": [
        "***Crawl data về giáo dục***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVJVY5UYZsBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "giaoduc_titles = []\n",
        "for i in range (1, 501):\n",
        "  url = \"https://vietnamnet.vn/vn/giao-duc/trang{}\".format(i)\n",
        "  soup = get_page_content(url)\n",
        "  h3_contents = soup.findAll('h3')\n",
        "  \n",
        "  new_titles = []\n",
        "  for h3_content in h3_contents:\n",
        "    if (h3_content.find('a')):\n",
        "      text = h3_content.find('a').text\n",
        "      new_titles.append(text)\n",
        "  \n",
        "  giaoduc_titles += new_titles\n",
        "  \n",
        "giaoduc_titles = list(set(giaoduc_titles))\n",
        "print(len(giaoduc_titles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDMEoE41Z6qe",
        "colab_type": "text"
      },
      "source": [
        "***Crawl data về pháp luật***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEK9gknAZ69-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "phapluat_titles = []\n",
        "for i in range (1, 501):\n",
        "  url = \"https://vietnamnet.vn/vn/phat-luat/trang{}\".format(i)\n",
        "  soup = get_page_content(url)\n",
        "  h3_contents = soup.findAll('h3')\n",
        "  \n",
        "  new_titles = []\n",
        "  for h3_content in h3_contents:\n",
        "    if (h3_content.find('a')):\n",
        "      text = h3_content.find('a').text\n",
        "      new_titles.append(text)\n",
        "  \n",
        "  phapluat_titles += new_titles\n",
        "  \n",
        "phapluat_titles = list(set(phapluat_titles))\n",
        "print(len(phapluat_titles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m63T4hk2aK2p",
        "colab_type": "text"
      },
      "source": [
        "***Crawl data về công nghệ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhy5h5WraLDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "congnghe_titles = []\n",
        "for i in range (1, 501):\n",
        "  url = \"https://vietnamnet.vn/vn/cong-nghe/trang{}\".format(i)\n",
        "  soup = get_page_content(url)\n",
        "  h3_contents = soup.findAll('h3')\n",
        "  \n",
        "  new_titles = []\n",
        "  for h3_content in h3_contents:\n",
        "    if (h3_content.find('a')):\n",
        "      text = h3_content.find('a').text\n",
        "      new_titles.append(text)\n",
        "  \n",
        "  congnghe_titles += new_titles\n",
        "  \n",
        "congnghe_titles = list(set(congnghe_titles))\n",
        "print(len(xongnghe_titles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYWl4VDjaZnU",
        "colab_type": "text"
      },
      "source": [
        "Kết thúc crawl data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubFD3sAeeqee",
        "colab_type": "text"
      },
      "source": [
        "## **4. Tiền xử lí dữ liệu:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyHzfv6Y822C",
        "colab_type": "text"
      },
      "source": [
        "> - Kiểm tra dữ liệu ta đã crawl về và thấy data hoàn toàn tốt, nên bước này không làm gì cả"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QULL7ueWx7SV",
        "colab_type": "text"
      },
      "source": [
        "## **5. Tổng kết dữ liệu:**\n",
        "\n",
        "> *    Thể thao: 7499 tiêu đề\n",
        "> *    Giáo dục: 7510 tiêu đề\n",
        "> *    Công nghệ: 7520 tiêu đề\n",
        "> *    Pháp luật: 7516 tiêu đề\n",
        "> *    Chính trị: 7145 tiêu đề\n",
        "> *    Kinh doanh: 7522 tiêu đề\n",
        "\n",
        "> Tổng cộng: 44712 tiêu đề"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6iUp2PeLPrE",
        "colab_type": "text"
      },
      "source": [
        "## **6. Tỉ lệ phân chia dữ liệu**\n",
        "\n",
        "> Train: 80%\n",
        "\n",
        "> Test: 20%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8W8ooroOUBE",
        "colab_type": "text"
      },
      "source": [
        "# **III. Các bước tiến hành train data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccK5q5SbOOFH",
        "colab_type": "text"
      },
      "source": [
        "## 1.Xử lý dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iET5qTllDtSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "77a4580c-726f-4c41-bc33-3362e651e556"
      },
      "source": [
        "%pip install pyvi   "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/e1/0e5bc6b5e3327b9385d6e0f1b0a7c0404f28b74eb6db59a778515b30fd9c/pyvi-0.1-py2.py3-none-any.whl (8.5MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5MB 3.8MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.18.5)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.7 pyvi-0.1 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUFjYixkO2Ju",
        "colab_type": "text"
      },
      "source": [
        "### **a) Tiến hành load dữ liệu:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuIWT_j2b-wD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "68c4981c-d33d-49e6-bd95-df8e1863f69b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khDqBrUOBMya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# đọc các file chứa nội dung cần thiết\n",
        "thethao = open('/content/drive/My Drive/NLP_data/TheThao/thethao_VNnet.txt','r')\n",
        "giaoduc = open('/content/drive/My Drive/NLP_data/GiaoDuc/giaoduc_VNnet.txt','r')\n",
        "phapluat = open('/content/drive/My Drive/NLP_data/PhapLuat/phapluat_VNnet.txt', 'r')\n",
        "congnghe = open('/content/drive/My Drive/NLP_data/CongNghe/congnghe_VNnet.txt', 'r')\n",
        "chinhtri = open('/content/drive/My Drive/NLP_data/ChinhTri/chinhtri_VNnet.txt', 'r')\n",
        "kinhdoanh = open('/content/drive/My Drive/NLP_data/KinhDoanh/kinhdoanh_VNnet.txt', 'r')\n",
        "kinhdoanh = kinhdoanh.read()\n",
        "thethao = thethao.read()\n",
        "giaoduc=giaoduc.read()\n",
        "phapluat = phapluat.read()\n",
        "congnghe = congnghe.read()\n",
        "chinhtri = chinhtri.read()\n",
        "# Tiến hành chia cắt data thành các tiêu đề khác nhau\n",
        "thethao = thethao.split('\\n')\n",
        "giaoduc = giaoduc.split('\\n')\n",
        "phapluat = phapluat.split('\\n')\n",
        "congnghe = congnghe.split('\\n')\n",
        "chinhtri = chinhtri.split('\\n')\n",
        "kinhdoanh = kinhdoanh.split('\\n')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHVTJuK2IbP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "79df13fd-7670-4fe7-a6af-a271afaf080b"
      },
      "source": [
        "print(len(thethao))\n",
        "print(len(giaoduc))\n",
        "print(len(phapluat))\n",
        "print(len(congnghe))\n",
        "print(len(chinhtri))\n",
        "print(len(kinhdoanh))\n",
        "# kích thước các chủ đề"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7499\n",
            "7510\n",
            "7516\n",
            "7520\n",
            "7145\n",
            "7522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQJaxZZtPKHO",
        "colab_type": "text"
      },
      "source": [
        "> *    Sử dụng thư viện *ViTokenizer* để xử lí văn bản tiếng Việt, mục đích là tách từ. Ví dụ câu: \"Ngôi trường mến yêu\", sau khi dùng *ViTokenzier* để xử lý thì ta sẽ thu về \"Ngôi trường mến_yêu\". Khi này câu sẽ có 3 từ là ngôi, trường, mến yêu.\n",
        "\n",
        "> *    Sử dụng *gensim* để loại bỏ những kí tự đặc biệt như: \".\", \",\", \"!\",.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI4XM4gpC9Rh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e71cdfd3-744d-4c97-fe48-16e5a8f53725"
      },
      "source": [
        "from pyvi import ViTokenizer # thư viện NLP tiếng Việt\n",
        "import numpy as np\n",
        "import gensim  #thư viện NLP\n",
        "X = []\n",
        "Y = []\n",
        "train_data = []\n",
        "for lines in thethao: #load data từ file the thao\n",
        "  lines = gensim.utils.simple_preprocess(lines)  # loại bỏ các kí tự đặc biệt, không cần thiết\n",
        "  lines = ' '.join(lines) \n",
        "  lines = ViTokenizer.tokenize(lines)   # tách câu ra thành các từ tiếng việt\n",
        "  lines = ''.join(lines)\n",
        "  \n",
        "  X.append(lines)\n",
        "  Y.append('thethao')\n",
        "\n",
        "for lines in giaoduc: #load data từ file giáo dục\n",
        "  lines = gensim.utils.simple_preprocess(lines)\n",
        "  lines = ' '.join(lines) \n",
        "  lines = ViTokenizer.tokenize(lines)\n",
        "  lines = ''.join(lines)\n",
        "  \n",
        "  X.append(lines)\n",
        "  Y.append('giaoduc')\n",
        "for lines in phapluat:  #load data từ file pháp luật\n",
        "  lines = gensim.utils.simple_preprocess(lines)\n",
        "  lines = ' '.join(lines) \n",
        "  lines = ViTokenizer.tokenize(lines)\n",
        "  lines = ''.join(lines)\n",
        "  \n",
        "  X.append(lines)\n",
        "  Y.append('phapluat')\n",
        "for lines in congnghe:  #load data từ file công nghệ\n",
        "  lines = gensim.utils.simple_preprocess(lines)\n",
        "  lines = ' '.join(lines) \n",
        "  lines = ViTokenizer.tokenize(lines)\n",
        "  lines = ''.join(lines)\n",
        " \n",
        "  X.append(lines)\n",
        "  Y.append('congnghe')\n",
        "for lines in chinhtri:  #laod data từ file chính trị\n",
        "  lines = gensim.utils.simple_preprocess(lines)\n",
        "  lines = ' '.join(lines) \n",
        "  lines = ViTokenizer.tokenize(lines)\n",
        "  lines = ''.join(lines)\n",
        "\n",
        "  X.append(lines)\n",
        "  Y.append('chinhtri')\n",
        "\n",
        "for lines in kinhdoanh: #load data từ file kinh doanh\n",
        "  lines = gensim.utils.simple_preprocess(lines)\n",
        "  lines = ' '.join(lines) \n",
        "  lines = ViTokenizer.tokenize(lines)\n",
        "  lines = ''.join(lines)\n",
        "\n",
        "  X.append(lines)\n",
        "  Y.append('kinhdoanh')\n",
        "print(len(X))\n",
        "print(len(Y))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44712\n",
            "44712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGqK4x0Ofv3K",
        "colab_type": "text"
      },
      "source": [
        "###**b) Xóa bỏ stop word:**\n",
        "Stop word được lấy từ\n",
        "> *    https://xltiengviet.fandom.com/wiki/Danh_s%C3%A1ch_stop_word\n",
        "> *    https://github.com/NguyenVanHieuBlog/vietnamese-stopwords/blob/master/stopwords.txt \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebB_rxTtfvND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_word = open('/content/drive/My Drive/NLP_data/stopword.txt') #đọc file stop word\n",
        "stop_word = stop_word.read()  #đọc file stop word\n",
        "stop_word = stop_word.split('\\n')\n",
        "stop_word = list(set(stop_word))  #lọc stop_word để tránh những stop word trùng nhau\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGL4slxvg5J9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bắt đầu xóa stop_word \n",
        "\n",
        "for i in range (0, len(X)):    # Load qua tất cả các headline có trong X\n",
        "  s_new = ''\n",
        "  for s in X[i].split(' '):   # Tách headline ra thành các từ\n",
        "    if s not in stop_word:    #Xem xét từ đó có trong danh sách stop word hay không, nếu không thì giữ lại\n",
        "      s_new = s_new + s + ' ' #Tạo headline mới với những stop word đã bị loại bỏ\n",
        "  X[i] = s_new                # Thay thế"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYULdp9pRQx0",
        "colab_type": "text"
      },
      "source": [
        "### **c) Phân chia dữ liệu:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEbs_JtORf81",
        "colab_type": "text"
      },
      "source": [
        "Dữ liệu được phân chia theo tỉ lệ 80% train, 20% test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdGwiKH3k98Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2b137b3b-13fe-4bae-c929-48d10cc6a384"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35769\n",
            "8943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3CH2pRYCTNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "272a4c3a-2d3c-4b83-c68e-41c919cc4085"
      },
      "source": [
        "import joblib\n",
        "\n",
        "path = '/content/drive/My Drive/NLP_data/X_train.sav'\n",
        "joblib.dump(X_train, path)\n",
        "\n",
        "#Bước này dùng để lưu tập train để dùng cho phần dự đoán "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/NLP_data/X_train.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLwos-VdRZGD",
        "colab_type": "text"
      },
      "source": [
        "### **d) Tiến hành xử lý dữ liệu:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqVf7TQzRebA",
        "colab_type": "text"
      },
      "source": [
        "Có nhiều phương pháp phân tích dữ liệu text, phổ biến là dùng *TfidfVectorizer* và đơn giản là sử dụng *CountVecotrize*. Ta sẽ tiến hành tìm hiểu 2 phương pháp xử lí dữ liệu text này"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiQPIvU7YyaG",
        "colab_type": "text"
      },
      "source": [
        "> *  ***CountVectorize:***\n",
        "\n",
        ">> - Đây là phương pháp tính số lần xuất hiện của một từ trong văn bản. Khi thực hiện, ta sẽ thu được một kết quả trả về một vector biểu diễn các từ và số lần từ đó xuất hiện có trong văn bản.\n",
        " \n",
        "\n",
        "> *    ***TfidfVectorizer***\n",
        "\n",
        ">> - Đây là phương pháp tính trọng số của từ xuất hiện trong văn bản. Trọng số càng lớn thì độ quan trọng của từ đó càng cao.\n",
        ">> - TF: là tần số từ đó xuất hiện trong văn bản. Vì 1 văn bản cần xử lý có thể dài ngắn khác nhau, nên để thấy được độ quan trọng của từ đó, ta có thể tính bằng tf(w,d) = f(w, d)/max({r_w, d | r_w ∈ d}).\n",
        "\n",
        ">>> Trong đó: \n",
        ">>> - tf(t, d): tần suất xuất hiện của từ t trong văn bản d\n",
        ">>> - f(t, d): Số lần xuất hiện của từ t trong văn bản d\n",
        ">>> - max({r_w,d | r_w ∈ d}): Số lần xuất hiện của từ có số lần xuất hiện nhiều nhất trong văn bản d\n",
        ">> - IDF: giúp đánh giá độ quan trọng của một từ bằng cách tính log nghịch đảo của tỉ lệ số văn bản xuất hiện từ đang xét với tổng số văn bản. Được tính bởi công thức idf(w, D) = log(|D|/{d∈D, w∈d}). Ta có thể một cách đơn giản là một từ mà văn bản nào mà nó cũng xuất hiện thì nó không quan trọng là mấy\n",
        ">>> Trong đó:\n",
        ">>> - idf(w, D): giá trị idf của từ w trong tập văn bản\n",
        ">>> - |D|: tổng số văn bản trong tập D\n",
        ">>> - {d ∈ D : t ∈ d}: số văn bản có từ w trong tập D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmvQdPxyBmFV",
        "colab_type": "text"
      },
      "source": [
        "CountVecotrize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PDiZ4zEFEDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import  CountVectorizer\n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "\n",
        "count_vect.fit(X_train) #tạo bộ từ vựng\n",
        "X_train_countvec = count_vect.transform(X_train)  #chuyển data dựa vào bộ từ vựng\n",
        "X_test_countvec = count_vect.transform(X_test) #chuyển data dựa vào bộ từ vựng"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-pTvkwwBoLT",
        "colab_type": "text"
      },
      "source": [
        "TfidfVectorize( Word Level )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGc1Dk7EZxM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer='word', max_features=100000)  #lựa chọn số từ vào vocabulary\n",
        "tfidf.fit(X_train)  #tạo bộ từ vựng\n",
        "X_train_tfidf_wordlevel =  tfidf.transform(X_train)  #chuyển data dựa vào bộ từ vựng\n",
        "X_test_tfidf_wordlevel =  tfidf.transform(X_test)  #chuyển data dựa vào bộ từ vựng"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HTBG22n0UvT",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành mã hóa label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ678y9UKEoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d13a69a2-4cbd-4ede-f719-952705926cd9"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "Y_train_encode = encoder.fit_transform(Y_train)\n",
        "Y_test_encode = encoder.fit_transform(Y_test)\n",
        "print(encoder.transform(['chinhtri', 'congnghe', 'giaoduc','kinhdoanh', 'phapluat', 'thethao']))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzGuOzgV0YEs",
        "colab_type": "text"
      },
      "source": [
        "## **2.Chọn model và tiến hành train**\n",
        "\n",
        "Sử dụng 3 model cơ bản để so sánh\n",
        "> *    LogisticRegression\n",
        "> *    RandomForestClassifier\n",
        "> *    LinearSVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6_TmaQgVGEN",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng bộ từ vựng được tạo bởi TfidfVectorizer word level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM7DKX6xTK4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "LR = LogisticRegression()\n",
        "LR_countvec = LogisticRegression()\n",
        "RFC_countvec = RandomForestClassifier()\n",
        "RFC = RandomForestClassifier()\n",
        "LSVC_countvec = LinearSVC()\n",
        "LSVC = LinearSVC()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7X8jKxW-qH4",
        "colab_type": "text"
      },
      "source": [
        "LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCFvcXwS0GmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "46beff75-3317-4bf6-ca46-9a27b5d5b3f3"
      },
      "source": [
        "LSVC.fit(X_train_tfidf_wordlevel, Y_train_encode)\n",
        "prediction=LSVC.predict(X_test_tfidf_wordlevel)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test_encode, prediction))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90      1397\n",
            "           1       0.90      0.89      0.89      1483\n",
            "           2       0.91      0.92      0.92      1507\n",
            "           3       0.86      0.87      0.87      1555\n",
            "           4       0.94      0.93      0.93      1434\n",
            "           5       0.98      0.98      0.98      1567\n",
            "\n",
            "    accuracy                           0.92      8943\n",
            "   macro avg       0.92      0.91      0.91      8943\n",
            "weighted avg       0.92      0.92      0.92      8943\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fap9v3lzm7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "8c72852b-c94c-4170-b624-624647c38a7f"
      },
      "source": [
        "LSVC_countvec.fit(X_train_countvec, Y_train_encode)\n",
        "prediction=LSVC_countvec.predict(X_test_countvec)\n",
        "print(classification_report(Y_test_encode, prediction))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88      1397\n",
            "           1       0.88      0.88      0.88      1483\n",
            "           2       0.89      0.92      0.90      1507\n",
            "           3       0.86      0.84      0.85      1555\n",
            "           4       0.93      0.92      0.92      1434\n",
            "           5       0.98      0.97      0.98      1567\n",
            "\n",
            "    accuracy                           0.90      8943\n",
            "   macro avg       0.90      0.90      0.90      8943\n",
            "weighted avg       0.90      0.90      0.90      8943\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWXpmXLxsdcO",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành lưu model LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvTFH83oshsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17afe4a7-ed6f-4183-cc50-f9169521df48"
      },
      "source": [
        "import joblib\n",
        "\n",
        "path = '/content/drive/My Drive/FinalModel/LSVC.sav'  #khởi tạo đường dẫn để lưu model\n",
        "joblib.dump(LSVC, path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/FinalModel/LSVC.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5ExkWMA-sba",
        "colab_type": "text"
      },
      "source": [
        "LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ0lPWhjmGdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "90f867a6-e47a-4378-d2da-894c37419d12"
      },
      "source": [
        "LR.fit(X_train_tfidf_wordlevel, Y_train_encode)\n",
        "prediction=LR.predict(X_test_tfidf_wordlevel)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test_encode, prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89      1397\n",
            "           1       0.89      0.88      0.89      1483\n",
            "           2       0.92      0.91      0.91      1507\n",
            "           3       0.83      0.88      0.86      1555\n",
            "           4       0.94      0.92      0.93      1434\n",
            "           5       0.98      0.97      0.97      1567\n",
            "\n",
            "    accuracy                           0.91      8943\n",
            "   macro avg       0.91      0.91      0.91      8943\n",
            "weighted avg       0.91      0.91      0.91      8943\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5zeGg3kz6sA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "e74a4c88-5847-4560-a580-a10671a238f1"
      },
      "source": [
        "LR_countvec.fit(X_train_countvec, Y_train_encode)\n",
        "prediction=LR_countvec.predict(X_test_countvec)\n",
        "print(classification_report(Y_test_encode, prediction))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89      1397\n",
            "           1       0.89      0.87      0.88      1483\n",
            "           2       0.91      0.91      0.91      1507\n",
            "           3       0.84      0.86      0.85      1555\n",
            "           4       0.94      0.91      0.93      1434\n",
            "           5       0.98      0.97      0.98      1567\n",
            "\n",
            "    accuracy                           0.90      8943\n",
            "   macro avg       0.91      0.90      0.90      8943\n",
            "weighted avg       0.91      0.90      0.91      8943\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWCP0d6OuFFj",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành lưu model LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWuaEjwnuI1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0e42a2a-078a-4aee-a4f7-f1394de9bd4f"
      },
      "source": [
        "import joblib\n",
        "\n",
        "path = '/content/drive/My Drive/FinalModel/LR.sav'  #khởi tạo đường dẫn để lưu model\n",
        "joblib.dump(LR, path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/FinalModel/LR.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Abg453v-vEO",
        "colab_type": "text"
      },
      "source": [
        "RandomForestClasifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkC4wUpo0N5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "71d52237-2c57-486b-8188-566622260a90"
      },
      "source": [
        "RFC.fit(X_train_tfidf_wordlevel, Y_train_encode)\n",
        "prediction=RFC.predict(X_test_tfidf_wordlevel)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test_encode, prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87      1397\n",
            "           1       0.88      0.84      0.86      1483\n",
            "           2       0.90      0.89      0.89      1507\n",
            "           3       0.78      0.83      0.81      1555\n",
            "           4       0.88      0.88      0.88      1434\n",
            "           5       0.97      0.96      0.96      1567\n",
            "\n",
            "    accuracy                           0.88      8943\n",
            "   macro avg       0.88      0.88      0.88      8943\n",
            "weighted avg       0.88      0.88      0.88      8943\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcSZ2l630Tc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "6ea5fed3-e890-464b-f730-5874b3c5211f"
      },
      "source": [
        "RFC_countvec.fit(X_train_countvec, Y_train_encode)\n",
        "prediction=RFC_countvec.predict(X_test_countvec)\n",
        "print(classification_report(Y_test_encode, prediction))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87      1397\n",
            "           1       0.88      0.84      0.86      1483\n",
            "           2       0.89      0.89      0.89      1507\n",
            "           3       0.79      0.83      0.81      1555\n",
            "           4       0.89      0.88      0.89      1434\n",
            "           5       0.97      0.96      0.96      1567\n",
            "\n",
            "    accuracy                           0.88      8943\n",
            "   macro avg       0.88      0.88      0.88      8943\n",
            "weighted avg       0.88      0.88      0.88      8943\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8geN_OhuL7Z",
        "colab_type": "text"
      },
      "source": [
        "Tiến hành lưu model RandomForestClasifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4otscYauP0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0254b0bb-ee80-4193-8e43-791a98ac7a48"
      },
      "source": [
        "import joblib\n",
        "\n",
        "path = '/content/drive/My Drive/FinalModel/RFC.sav'  #khởi tạo đường dẫn để lưu model\n",
        "joblib.dump(RFC, path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/FinalModel/RFC.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpfiQgOg_JJI",
        "colab_type": "text"
      },
      "source": [
        "#**IV - Fine Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtLBoLuB_VYt",
        "colab_type": "text"
      },
      "source": [
        "##**1. Sử dụng TfidfVectorize với ngram-word level**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhhoZYkYAE__",
        "colab_type": "text"
      },
      "source": [
        "TfidfVectorize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnDg10e4_uzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_ngram = TfidfVectorizer(analyzer='word', max_features=100000, ngram_range=(2,3))  #lựa chọn số từ vào vocabulary\n",
        "tfidf_ngram.fit(X_train)  #tạo bộ từ vựng\n",
        "X_train_tfidf_nwordlevel =  tfidf_ngram.transform(X_train)  #chuyển data dựa vào bộ từ vựng\n",
        "X_test_tfidf_nwordlevel =  tfidf_ngram.transform(X_test)  #chuyển data dựa vào bộ từ vựng"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-IPITjlAZ0K",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng TruncatedSVD nhằm giảm chiều dữ liệu của ma trận nhưng vẫn giữ nguyên các đặc trưng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR6sjxUQ0ZGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=300, random_state=42) #Ta sẽ giảm số chiều xuống còn 300\n",
        "svd.fit(X_train_tfidf_nwordlevel)\n",
        "X_train_svd_nwordlevel = svd.transform(X_train_tfidf_nwordlevel)\n",
        "X_test_svd_nwordlevel = svd.transform(X_test_tfidf_nwordlevel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIAQpmkJAqwG",
        "colab_type": "text"
      },
      "source": [
        "##**2. Sử dụng TfidfVectorize với ngram-char level**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQW2v1azkfEh",
        "colab_type": "text"
      },
      "source": [
        "TfidfVectorize ngram-char level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiZx0fnqjlG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_ngram = TfidfVectorizer(analyzer='char', max_features=100000, ngram_range=(2,3))  #lựa chọn số từ vào vocabulary\n",
        "tfidf_ngram.fit(X_train)  #tạo bộ từ vựng\n",
        "X_train_tfidf_ncharlevel =  tfidf_ngram.transform(X_train)  #chuyển data dựa vào bộ từ vựng\n",
        "X_test_tfidf_ncharlevel =  tfidf_ngram.transform(X_test)  #chuyển data dựa vào bộ từ vựng"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtWvKuIOklcB",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng TruncatedSVD nhằm giảm chiều dữ liệu của ma trận nhưng vẫn giữ nguyên các đặc trưng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgJpWM8HkLae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=300, random_state=42)\n",
        "svd.fit(X_train_tfidf_ncharlevel)\n",
        "X_train_svd_ncharlevel = svd.transform(X_train_tfidf_ncharlevel)\n",
        "X_test_svd_ncharlevel = svd.transform(X_test_tfidf_ncharlevel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yle194Un1EZc",
        "colab_type": "text"
      },
      "source": [
        "**Thử train data với mô hình DNN đơn giản**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFWWTPOQkxdp",
        "colab_type": "text"
      },
      "source": [
        "Ở đây em sẽ sử dụng TruncatedSVD với dữ liệu ngram-word level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y80VnaJC1OQ6",
        "colab_type": "text"
      },
      "source": [
        "Phân chia dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xjpyGcgIF6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_new, X_val_new, Y_train_new, Y_val_new = train_test_split(X_train_svd_nwordlevel, Y_train_encode, test_size=0.15, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zf8P0xJKFvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Reshape, Bidirectional, GRU\n",
        "from sklearn import metrics\n",
        "from keras import Model\n",
        "from keras import optimizers\n",
        "from keras import Input\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpk4RQSL1Vyj",
        "colab_type": "text"
      },
      "source": [
        "*Khởi tạo mô hình*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIFMhDu24DK1",
        "colab_type": "text"
      },
      "source": [
        "Công thức hàm kích hoạt ReLU: f(x) = max(0,x), do đó đơn giản hàm này lọc các giá trị nhỏ hơn 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoO4ReqeHN1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "501cff8e-def3-47c7-d1b7-3d0c5af31291"
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "from tensorflow import sparse\n",
        "input_layer = Input(shape=(300,))  #Khởi tạo một layer input với shpe = (300,) vì ở giai đoạn giảm chiều dữ liệu, em đã giảm xuống còn 300\n",
        "layer = Dense(512, activation='relu')(input_layer)  #Hiden layer với số neuron trong layer, hàm kích hoạt là hàm relu\n",
        "layer = Dense(512, activation='relu')(layer)\n",
        "layer = Dense(256, activation='relu')(layer)\n",
        "layer = Dense(128, activation='relu')(layer)\n",
        "layer = Dense(64, activation='relu')(layer)\n",
        "output_layer = Dense(6, activation='softmax')(layer)   # Khởi tạo layer out_put, vì có 6 class nên số neuron hàm out_put là 6, hàm kích hoạt out_put sẽ là softmax\n",
        "    \n",
        "DNN = Model(input_layer, output_layer)\n",
        "DNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "DNN.fit(X_train_new, Y_train_new, validation_data=(X_val_new, Y_val_new), epochs=10, batch_size=512)\n",
        "      \n",
        "val_predictions = DNN.predict(X_val_new)\n",
        "test_predictions = DNN.predict(X_test_svd_nwordlevel)\n",
        "val_predictions = val_predictions.argmax(axis=-1)\n",
        "test_predictions = test_predictions.argmax(axis=-1)\n",
        "\n",
        "print(\"Validation accuracy: \", metrics.accuracy_score(val_predictions, Y_val_new))  #xác nhận chính xác\n",
        "print(\"Test accuracy: \", metrics.accuracy_score(test_predictions, Y_test_encode))   #test chính xác"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 3s 42ms/step - loss: 1.3201 - accuracy: 0.5043 - val_loss: 0.9824 - val_accuracy: 0.6223\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 2s 41ms/step - loss: 0.9092 - accuracy: 0.6696 - val_loss: 0.8574 - val_accuracy: 0.6906\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.8271 - accuracy: 0.7012 - val_loss: 0.8134 - val_accuracy: 0.7136\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.7787 - accuracy: 0.7159 - val_loss: 0.8050 - val_accuracy: 0.7083\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 0.7409 - accuracy: 0.7301 - val_loss: 0.8053 - val_accuracy: 0.7067\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 0.7212 - accuracy: 0.7386 - val_loss: 0.7618 - val_accuracy: 0.7287\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 2s 41ms/step - loss: 0.7137 - accuracy: 0.7371 - val_loss: 0.7683 - val_accuracy: 0.7294\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 2s 39ms/step - loss: 0.7091 - accuracy: 0.7375 - val_loss: 0.8112 - val_accuracy: 0.7059\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.6976 - accuracy: 0.7414 - val_loss: 0.7698 - val_accuracy: 0.7216\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 3s 43ms/step - loss: 0.6855 - accuracy: 0.7461 - val_loss: 0.7592 - val_accuracy: 0.7275\n",
            "Validation accuracy:  0.7275437942601566\n",
            "Test accuracy:  0.7321927764732192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMKPAg90n0Hj",
        "colab_type": "text"
      },
      "source": [
        "Và thử với LinearSVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhANWa7woMt9",
        "colab_type": "text"
      },
      "source": [
        "> * Trong trường hợp ta chưa giảm chiều dữ liệu với TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3eT0E1WmcM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ed454734-9555-441b-9798-c8c9a2d8a5b8"
      },
      "source": [
        "LSVC_finetuning = LinearSVC()\n",
        "LSVC_finetuning.fit(X_train_tfidf_nwordlevel, Y_train_encode)\n",
        "prediction=LSVC_finetuning.predict(X_test_tfidf_nwordlevel)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test_encode, prediction))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.83      0.85      1397\n",
            "           1       0.68      0.84      0.75      1483\n",
            "           2       0.88      0.81      0.85      1507\n",
            "           3       0.78      0.74      0.76      1555\n",
            "           4       0.89      0.89      0.89      1434\n",
            "           5       0.95      0.89      0.92      1567\n",
            "\n",
            "    accuracy                           0.83      8943\n",
            "   macro avg       0.84      0.83      0.84      8943\n",
            "weighted avg       0.84      0.83      0.84      8943\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bT5HwlYoSsr",
        "colab_type": "text"
      },
      "source": [
        "> * Trong trường hợp đã giảm chiều dữ liệu với TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovqAz63gofUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2fa5dfd8-241d-44b8-a222-18c80dc94a08"
      },
      "source": [
        "LSVC_finetuning = LinearSVC()\n",
        "LSVC_finetuning.fit(X_train_svd_nwordlevel, Y_train_encode)\n",
        "prediction=LSVC_finetuning.predict(X_test_svd_nwordlevel)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test_encode, prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.63      0.73      1397\n",
            "           1       0.41      0.81      0.54      1483\n",
            "           2       0.85      0.60      0.70      1507\n",
            "           3       0.63      0.53      0.58      1555\n",
            "           4       0.83      0.75      0.79      1434\n",
            "           5       0.89      0.72      0.80      1567\n",
            "\n",
            "    accuracy                           0.67      8943\n",
            "   macro avg       0.74      0.67      0.69      8943\n",
            "weighted avg       0.74      0.67      0.69      8943\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEGbl6NFniZc",
        "colab_type": "text"
      },
      "source": [
        "#**V- NHẬN XÉT:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfzpM6g0nnZ5",
        "colab_type": "text"
      },
      "source": [
        "**TRONG TRƯỜNG HỢP CHƯA FINE TUNING**\n",
        "* Ta thấy accuracy của model LinearSVC có accuracy cao nhất (0.92), sau đó là LogisticRegression với accuracy 0.91 và sau cùng là RandomForestClasifier với accuracy là 0.88 (Trường hợp sử dụng TfidfVectorizer word level)\n",
        "* Trường hợp sử dụng CountVectorizer, accuracy của model LinearSVC và LogisticRegression đạt được 0.90 và RandomForestClassifier đạt được 0.88\n",
        "\n",
        "=> Feature Engineering sử dụng TfidfVectorizer word level có vẻ tốt hơn CountVectorizer một chút\n",
        "* Accuracy khá ổn nhờ tập data tốt, và nhiều. Bước xử lý dữ liệu chi tiết\n",
        "\n",
        "**TRONG TRƯỜNG HỢP FINE TUNING**\n",
        "* Ta mong muốn trong trường hợp này một kết quả tốt hơn trước khi chưa fine tuning. Nhưng...không, ta nhận lại một kết quả không khả quan cho lắm.\n",
        "* Sau khi khi tạo bộ từ vựng với nword level, ngram_range=(2,3) thì kết quả khi sử dụng model LinearSVC không còn tốt như trước, mà cụ thể là bây giờ accuracy chỉ còn 0.83\n",
        "* Sau khi giảm chiều dữ liệu:\n",
        "   * Dùng mô hình DNN cũng không khả quan cho lắm, accuracy cho tập val và test lần lượt là 0.728 và 0.732\n",
        "   * Dùng với model LinearSVC kết quả còn tệ hơn, accuracy chỉ còn 0.67\n",
        "   * Có thể cách fine tuning của em chưa thực sự đạt hiệu quả, mà trái lại, nó đem đến nhiều bất lợi trong quá trình train và predict\n",
        "   * Mô hình DNN chưa thực sự tốt với tập dữ liệu như thế này, cần phải khắc phục mô hình"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENko6Rm4R6EW",
        "colab_type": "text"
      },
      "source": [
        "#**V - Dự đoán:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQJJ7CqRrRoH",
        "colab_type": "text"
      },
      "source": [
        "Ta tiến hành dự đoán với mô hình LinearSVC "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrhQqvxD1be-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_app, X_test_app, Y_train_app, Y_test_app = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yP8FBEOkVJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(encoder.transform(['chinhtri', 'congnghe', 'giaoduc', 'kinhdoanh', 'phapluat', 'thethao']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-h3i1qtmzLi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0ef534ff-54ed-4ffe-cf8f-6555955d7a8a"
      },
      "source": [
        "import joblib\n",
        "\n",
        "lines = input()   #input tiêu đề muốn dự đoán\n",
        "\n",
        "#các bước xử lý tiêu đề đưa vào\n",
        "lines = gensim.utils.simple_preprocess(lines)\n",
        "lines = ' '.join(lines) \n",
        "lines = ViTokenizer.tokenize(lines)\n",
        "lines = ''.join(lines)\n",
        "count_vect = TfidfVectorizer(analyzer='word', max_features=100000)\n",
        "lines = [lines]\n",
        "count_vect.fit(X_train_app)\n",
        "lines = count_vect.transform(lines)\n",
        "#kết thúc xử lý input\n",
        "\n",
        "model = joblib.load('/content/drive/My Drive/FinalModel/LSVC.sav')\n",
        "\n",
        "prediction = model.predict(lines)\n",
        "if (prediction==0):\n",
        "  print('Thuộc chủ đề chính trị')\n",
        "if (prediction==1):\n",
        "  print('Thuộc chủ đề công nghệ')\n",
        "if (prediction==2):\n",
        "  print('Thuộc chủ đề giáo dục')\n",
        "if (prediction==3):\n",
        "  print('Thuộc chủ đề kinh doanh')\n",
        "if (prediction==4):\n",
        "  print('Thuộc chủ đề pháp luật')\n",
        "if (prediction==5):\n",
        "  print('Thuộc chủ đề thể thao')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bộ trưởng bộ y tế đề nghị tự bảo vệ bản thân\n",
            "Thuộc chủ đề chính trị\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MdkSDDYvAh7",
        "colab_type": "text"
      },
      "source": [
        "#**VI - XÂY DỰNG MÔ HÌNH DỰ ĐOÁN VỚI FLASK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp2s5kQCX4Bx",
        "colab_type": "text"
      },
      "source": [
        "Code được up lên github:\n",
        "https://github.com/hoangnhan12-arc/CS114.K21.KHTN/tree/master/FINAL_MACHINELEARNING\n",
        "\n",
        "Link video demo youtube: \n",
        "https://www.youtube.com/watch?v=tMEb_1Ici8Q\n",
        "\n",
        "Tài liệu tham khảo: \n",
        "https://github.com/NguyenVanHieuBlog/programing-language-identify"
      ]
    }
  ]
}
